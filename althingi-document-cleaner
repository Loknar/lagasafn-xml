#!/usr/bin/env python
# althingi-document-cleaner
# Version 0.1

from bs4 import BeautifulSoup
import codecs
import urllib
import re
import roman

import os
import sys

import settings

from formencode.doctest_xml_compare import xml_compare
from lxml import etree
from lxml.builder import E
from sys import stderr
from sys import stdout

from contenthandlers import generate_ancestors
from contenthandlers import separate_sentences

from utils import Matcher
from utils import order_among_siblings
from utils import strip_links
from utils import strip_markers
from utils import super_iter
from utils import xml_lists_identical

CURRENT_PARLIAMENT_VERSION = '148a'

LAW_FILENAME = CURRENT_PARLIAMENT_VERSION + '/%d%s.html' # % (law_year, law_num)
CLEAN_FILENAME = 'cleaned/%d-%d.html' # % (law_year, law_num)
XML_FILENAME = 'xml/%d.%d.%s.xml' # % (law_year, law_num, parliament_version)

def clean_content(content):
    # Decode ISO-8859-1 character encoding.
    #content = content.decode('ISO-8859-1')

    # Replace HTML-specific space for normal space.
    content = content.replace('&nbsp;', ' ')

    # Make sure that horizontal bar tags are closed properly.
    content = content.replace('<hr>', '<hr />')

    # Make sure that linebreak tags are closed properly.
    content = content.replace('<br>', '<br />')

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove markers for previous changes and removed content.
        content = content.replace('[', '').replace(']', '')
        content = content.replace('…', '').replace('&hellip;', '')

    # Remove links to website
    #strings_to_remove = (
    #    u'Ferill málsins á Alþingi.',
    #    u'Frumvarp til laga.',
    #)
    #for s in strings_to_remove:
    #    content = content.replace(s, '')

    # Make sure that image tags are closed properly.
    e = re.compile(r'<img ([^>]*)>', re.IGNORECASE)
    content = e.sub(r'<img \1 />', content)

    # Remove <a id=""> tags which are unclosed and seem without purpose.
    # For example, see source of page: http://www.althingi.is/altext/143/s/0470.html
    content = content.replace('<a id="">', '')

    # Find the law content and exit if it does not exist
    soup_law = BeautifulSoup(content, 'html5lib').find('html')
    if soup_law is None:
        return None

    soup = BeautifulSoup(soup_law.__str__(), 'html5lib') # Parse the law content

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove superscripts indicating previous change. Only removes them when
        # they are found outside of footnotes.
        superscripts = soup.find_all('sup')
        for s in superscripts:
            if s.parent.name != 'small' and re.match('^\d{1,3}\)$', s.text):
                s.extract()

    # Remove links
    #anchors = soup.find_all('a')
    #for a in anchors:
    #    a.replace_with(a.text)

    # Remove tags entirely irrelevant to content
    #tags_to_remove = ['small'] # Previously also ['hr', 'script', 'noscript', 'head']
    #for target_tag in tags_to_remove:
    #    [s.extract() for s in soup(target_tag)]

    # Remove empty tags, but only if they're empty
    empty_tags_to_remove = ['p', 'h2', 'i']
    for target_tag in empty_tags_to_remove:
        empty_tags = soup.find_all(lambda tag: tag.name == target_tag and not tag.contents and (
            tag.string is None or not tag.string.strip()
        ))
        [empty_tag.extract() for empty_tag in empty_tags]

    # Keep consecutive <br />s only at 2 at most
    brs_in_a_row = 0
    all_tags = soup.find_all()
    for t in all_tags:
        if t.name == 'br':
            if brs_in_a_row >= 2:
                t.extract()
            else:
                brs_in_a_row = brs_in_a_row + 1
        else:
            brs_in_a_row = 0

    # Replace <html> and <body> tags' with <div>s.
    '''
    body_tag = soup.find('body')
    if body_tag is not None:
        body_tag.attrs['id'] = 'body_tag'
        body_tag.name = 'div'
    html_tag = soup.find('html')
    html_tag.attrs['id'] = 'html_tag'
    html_tag.name = 'div'
    '''

    # Add charset tag
    charset_tag = soup.new_tag('meta', charset='utf-8')
    soup.insert(0, charset_tag)

    xhtml = soup.prettify()

    # Final cleanup at text-stage.
    xhtml = xhtml.replace(' <!-- Tab -->\n  ', '&nbsp;&nbsp;&nbsp;&nbsp;')

    return xhtml


def clean_law(law_num, law_year):
    with codecs.open(LAW_FILENAME % (law_year, str(law_num).zfill(3)), 'r', 'ISO-8859-1') as infile:
        raw_content = infile.read()
        infile.close()

    content = clean_content(raw_content)

    if content is None:
        stdout.write(' failed.\n')
        stderr.write('Error: Law %d/%d does not seem to exist\n' % (law_year, law_num))
        quit(1)

    if not os.path.isdir(os.path.dirname(CLEAN_FILENAME)):
        os.mkdir(os.path.dirname(CLEAN_FILENAME))

    with open(CLEAN_FILENAME % (law_year, law_num), 'w') as clean_file:
        clean_file.write(content)
        clean_file.close()


def make_xml(law_num, law_year, parliament_version):

    # Make sure that the XML output directory exists.
    if not os.path.isdir(os.path.dirname(XML_FILENAME)):
        os.mkdir(os.path.dirname(XML_FILENAME))

    # Construct the output XML object.
    law = E.law('', {'nr': str(law_num), 'year': str(law_year), 'parliament': parliament_version})

    # Open and read the cleaned HTML version of the law.
    with open(CLEAN_FILENAME % (law_year, law_num)) as clean_file:
        lines = super_iter(clean_file.readlines())
        clean_file.close()

    # Keeps track of the turn of events. We can query this list to check for
    # example whether the name of the document has been processed, or what the
    # last thing to be processed was. This gives us context when determining
    # what to do next.
    trail = ['start']

    # See utils.py.
    matcher = Matcher()

    # Functions for collecting heaps of text, then returning it all in one go
    # and resetting the collection for the next time we need to collect a
    # bunch of text.
    def collect(string):
        if not hasattr(collect, 'collection'):
            collect.collection = []
        collect.collection.append(string.strip())
    def uncollect():
        result = ' '.join(collect.collection).strip()
        collect.collection = []
        return result

    # Will collect lines until the given string is found, and then return the
    # collected lines.
    def collect_until(lines, end_string):
        done = False
        while not done:
            line = next(lines).strip()
            if matcher.check(line, end_string):
                done = True
                continue
            collect(line)

        total = uncollect().strip()

        return total

    # Checks how much iteration is required to hit a line that matches the
    # given regex. Optional limit parameter allows limiting search to a specific
    # number of lines into the future.
    def occurrence_distance(lines, regex, limit=None):
        i = 0
        line = lines.peek(i)
        while line is not None and (limit is None or i <= limit):
            line = line.strip()
            if matcher.check(line, regex):
                return i

            i += 1
            line = lines.peek(i)

        return None

    # Scrolls the lines until the given string is found. It works internally
    # the same as the collect_until-function, but is provided here with a
    # different name to provide a semantic distinction in the code below.
    scroll_until = collect_until

    # Objects that help us figure out the current state of affairs. These
    # variables are used between iterations, meaning that whenever possible,
    # their values should make sense at the end of the processing of a
    # particular line or clause. Never put nonsense into them because it will
    # completely confuse the processing elsewhere.
    chapter = None
    art = None
    subart = None

    # The cleaned document that we're processing is expected to put every tag,
    # both its opening and closing, on a separate line. This allows us to
    # browse the HTML contents on a per-line basis.
    for line in lines:
        line = line.strip()

        if line == '<h2>':
            # Parse law name.
            name = collect_until(lines, '</h2>')

            law.append(E.name(name))

            trail.append('name')

        elif line == '<strong>':
            if trail[-1] == 'name':
                # Parse the num and date, which appears directly below the law name.
                num_and_date = collect_until(lines, '</strong>')

                law.append(E('num-and-date', num_and_date))

                trail.append('num-and-date')

        elif line == '<hr/>' and trail[-1] == 'num-and-date':
            # Parse the whole clause about which minister the law refers to.
            # It contains HTML goo, but we'll just let it float along. It's
            # not even certain that we'll be using it, but there's no harm in
            # keeping it around.
            minister_clause = collect_until(lines, '<hr/>')

            law.append(E('minister-clause', minister_clause))

            trail.append('minister-clause')

        # Chapters are found by finding a <b> tag that comes right after a
        # <br/> tag that occurs after the ministerial clause is done.
        elif line == '<b>' and 'minister-clause' in trail and lines.peek(-1).strip() == '<br/>':
            # Parse what we will believe to be a chapter.

            # Chapter names are a bit tricky. They may be divided into two <b>
            # clauses, in which case the former one is what we call a nr-title
            # (I. kafli, II. kafli etc.), and then a name describing its
            # content (Almenn ákvæði, Tilgangur og markmið etc.).
            #
            # Sometimes however, there is only one <b> and not two. In these
            # cases, there is no nr-title and only a name. Here we check 3
            # lines into the future to see if there's another <b> tag coming
            # (because we know that the former <b>text</b> clause will be
            # precisely 3 lines), and if so, we'll process the nr-title and
            # name, but otherwise we will only process the name and skip
            # nr-title altogether.
            if lines.peek(3).strip() == '<b>':
                chapter_nr_title = collect_until(lines, '</b>')

                # Let's see if we can figure out the number of this chapter.
                # We're going to assume the format "II. kafli" for the second
                # chapter, and "II. kafli B." for the second chapter B, and in
                # those examples, nr-titles will be "2" and "2b" respectively.
                t = strip_markers(chapter_nr_title)
                nr = str(roman.fromRoman(t[0:t.index('.')]))
                alpha = t[t.index('kafli') + 6:].strip('.')
                if alpha:
                    nr += alpha.lower()
                del t

                scroll_until(lines, '<b>')
                chapter_name = collect_until(lines, '</b>')

                chapter = E.chapter(
                    {'nr': str(nr)},
                    E('nr-title', chapter_nr_title),
                    E('name', chapter_name)
                )

            else:
                chapter_name = collect_until(lines, '</b>')

                chapter = E.chapter(
                    E('name', chapter_name)
                )

            # Some laws have a chapter for temporary clauses, which may be
            # named something like "Bráðabirgðaákvæði", "Ákvæði til
            # bráðabirgða" and probably something else as well. We will assume
            # that a chapter name that includes that string "bráðabirgð" is a
            # chapter for temporary clauses and furthermore that the string
            # does NOT appear in any other kind of chapter.
            if 'bráðabirgð' in chapter_name.lower():
                chapter.attrib['type'] = 'temporary-clauses'

            law.append(chapter)

            trail.append('chapter')

        elif line == '<img alt="" height="11" src="/lagas/sk.jpg" width="11"/>':
            # Parse an article.
            scroll_until(lines, '<b>')
            art_nr_title = collect_until(lines, '</b>')

            clean_art_nr_title = strip_markers(art_nr_title)

            # Hopefully this stays None. Not because anything will break
            # otherwise, but because Roman numerals suck ass.
            art_roman_nr = None

            # Analyze the displayed article name.
            try:
                # A typical article is called something like "13. gr." or
                # "13. gr. b". The common theme among typical articles is that
                # the string ". gr." will appear in them somewhere. Anything
                # before it is the article number. Anything after it, is an
                # extra thing which is appended to article names when new
                # articles are placed between two existing ones. For example,
                # if there already are articles 13 and 14 but the legislature
                # believes that a new article properly belongs between them,
                # the article will probably be called "13. gr. a". We would
                # want that translated into an sortable `art_nr` f.e. "13a".

                # Find index of common string. If the string does not exist,
                # it's some sort of a special article. A ValueError will be
                # raised and we'll deal with it below.
                gr_index = clean_art_nr_title.index('. gr.')

                # Determine the numeric part of the article's name.
                art_nr = clean_art_nr_title[0:gr_index]

                # Occasionally an article number actually covers a range, so
                # far only seen when multiple articles have been removed and
                # are thus collectively empty. We check for the pattern here
                # and reconstruct it if needed.
                if matcher.check(clean_art_nr_title, '(\d+)\.–(\d+)'):
                    from_art_nr, to_art_nr = matcher.result()
                    art_nr = '%s-%s' % (from_art_nr, to_art_nr)

                # Check if there is an extra part to the name which we'll want
                # appended to the `art_nr`.
                #
                # Note: len('.gr.') + 1 = 6
                art_nr_extra = clean_art_nr_title[gr_index+6:].strip().strip('.')
                if len(art_nr_extra):
                    art_nr = '%s%s' % (art_nr, art_nr_extra)

            except ValueError:
                # This means that the article's name is formatted in an
                # unconventional way. Typically this occurs only in temporary
                # clauses that tend to be numbered with some stupid fucking
                # Roman bullshit.
                art_nr = None
                try:
                    art_roman_nr = str(roman.fromRoman(clean_art_nr_title.strip('.')))
                except roman.InvalidRomanNumeralError:
                    # Good. Fuck Roman numerals.
                    pass

            # Create the tags, configure them and append to the chapter.
            art = E('art', E('nr-title', art_nr_title))
            if art_nr is not None:
                art.attrib['nr'] = art_nr
            if art_roman_nr is not None:
                art.attrib['roman-nr'] = art_roman_nr
                art.attrib['number-type'] = 'roman'
            chapter.append(art)

            # Check if the next line is an <em>, because if so, then the
            # article has a name title and we need to grab it. Note that not
            # all articles have names.
            if lines.peek().strip() == '<em>':
                scroll_until(lines, '<em>')
                art_name = collect_until(lines, '</em>')

                art.append(E('name', art_name))

            # Check if the article is empty aside from markers that need to be
            # included in the article <nr-title> or <name> (depending on
            # whether <name> exists at all).
            while lines.peek().strip() in ['…', ']']:
                marker = collect_until(lines, '</sup>')
                art.getchildren()[-1].text += ' ' + marker + ' </sup>'

            trail.append('art-nr')

            # There can be no current subarticle if we've just discovered a
            # new article.
            subart = None

        elif matcher.check(line, '<img .+ id="[GB](\d+)[A-Z]?M(\d+)" src=".+\/hk.jpg" .+\/>'):
            art_nr, subart_nr = matcher.result()

            # Check how far we are from the typical subart end.
            linecount_to_br = occurrence_distance(lines, '<br/>')

            # Check if there's a table inside the subarticle.
            linecount_to_table = occurrence_distance(lines, '<\/table>', linecount_to_br)

            # If a table is found inside the subarticle, we'll want to end the
            # subarticle when the table ends.
            if linecount_to_table is not None:
                # We must append the string '</table>' because it gets left
                # behind by the collet_until function.
                content = collect_until(lines, '</table>') + '</table>'
            else:
                # Everyting is normal.
                content = collect_until(lines, '<br/>')

            subart = E('subart', {'nr': subart_nr })
            sens = separate_sentences(strip_links(content))
            for sen in sens:
                subart.append(E('sen', sen))
            art.append(subart)

            trail.append('subart')

        elif matcher.check(line, '<span id="G(\d+)([0-9A-Z]*)L(\d+)">'):
            numart_nr = strip_markers(lines.peek().strip().strip('.'))

            # Dictates where we will place this numart.
            parent = None

            if trail[-1] == 'numart':
                # `prev_numart` is only defined here for readability. `numart` hasn't
                # been set yet, so it's still equivalent to the previous
                # `numart`, so technically we could just use `numart` instead.
                # But `numart` is going to change later, so we'd rather be
                # clear on the code semantics when using `numart` but still
                # referring to the previous one.
                prev_numart = numart

                prev_numart_nr = prev_numart.attrib['nr']

                # Check if the type of the numart has changed from numeric to
                # alphabetic or vice versa.
                different_type = any([
                    prev_numart_nr.isdigit() and not numart_nr.isdigit(),
                    not prev_numart_nr.isdigit() and numart_nr.isdigit()
                ])

                if prev_numart_nr.isdigit():
                    expected_numart_nr = str(int(prev_numart_nr) + 1)
                else:
                    expected_numart_nr = chr(int(ord(prev_numart_nr)) + 1)

                if expected_numart_nr != numart_nr or different_type:
                    if numart_nr == 'a' or (numart_nr.isdigit() and int(numart_nr) == 1):
                        # A new list has started within the one we were
                        # already processing, which we can tell because there
                        # was a `numart` before this one, but this `numart`
                        # says it's at the beginning, being either 'a' or 1.
                        # In this case, we'll choose the previous `numart` as
                        # the parent, so that this new list will be inside the
                        # previous one.
                        parent = prev_numart
                    else:
                        # A different list is being handled now, but it's not
                        # starting at the beginning (is neither 'a' nor 1).
                        # This means that we've been dealing with a sub-list
                        # which has now finished, so we want to continue
                        # appending this `numart` to the parent of the parent
                        # of the list we've been working on recently, which is
                        # the same parent as the nodes that came before we
                        # started the sub-list.
                        parent = prev_numart.getparent().getparent()
                else:
                    # This `numart` is simply the next one, so we'll want to
                    # append it to whatever node that the previous `numart`
                    # was appended to.
                    parent = prev_numart.getparent()

            # A parent may already be set above if `numart` currently being
            # handled is not the first one in its parent article/subarticle.
            # However, if it is indeed the first one, we need to figure out
            # where to place it. It can be placed wither in a subarticle or in
            # some cases, directly into an article without a subarticle.
            if parent is None:
                if subart is not None:
                    parent = subart
                else:
                    # We sure as $h17 assume "art" exists.
                    parent = art

            # Create numerical article.
            numart = E('numart', {'nr': numart_nr })

            # Add the numerical article to its parent.
            parent.append(numart)

            numart_nr_title = collect_until(lines, '</span>')
            numart.append(E('nr-title', numart_nr_title))
            if not numart_nr_title.strip('.').strip('[').isdigit():
                numart.attrib.update({'type': 'alphabet'})

            if lines.peek().strip() == '<i>':
                # Looks like this numerical article has a name.
                scroll_until(lines, '<i>')
                numart_name = collect_until(lines, '</i>')

                numart.append(E('name', numart_name))

            # Read in the remainder of the content.
            content = collect_until(lines, '<br/>')

            # Split the content into sentences.
            sens = separate_sentences(strip_links(content))

            # Check if this numart is actually just a content-less container
            # for a sub-numart, by checking if the beginning of the content is
            # in fact the starting of a new list, numeric or alphabetic.
            possible_nr_title = strip_markers(sens[0]) if len(sens) else ''
            if possible_nr_title in ['a.', '1.']:
                new_numart_nr = possible_nr_title.strip('.')

                # Instead of adding the found sentences to the numart that
                # we've just made above, we'll create an entirely new numart,
                # called new_numart, and add that to the current numart.
                new_numart = E(
                    'numart',
                    {
                        'nr': new_numart_nr,
                        # The style-note is to communicate information to a
                        # possible layouting mechanism. In the official
                        # documents, a sub-numart that appears this way is not
                        # shown in a new line as normally, but rather inside
                        # its parent as if it were content. It's the layouting
                        # mechanism's responsibility to react to this
                        # information, if needed.
                        'style-note': 'inline-with-parent'
                    },
                    # Note that we go back for the 'sens' list because we'll
                    # want to include markers that might be there, but have
                    # been removed from `possible_nr_title` for comparison
                    # purposes.
                    E('nr-title', sens[0])
                )

                # Mark the new numart as alphabetic, if appropriate.
                if not new_numart_nr.isdigit():
                    new_numart.attrib['type'] = 'alphabet'

                # The first entity in the list will be the nr-title, which
                # we've already used and we don't want in the content, so
                # popped out here.
                sens.pop(0)

                # Add the sentences to the new numart.
                for sen in sens:
                    new_numart.append(E('sen', sen))

                # Add the new numart to the current numart.
                numart.append(new_numart)

                # Make sure that future iterations recognize the new numart as
                # the last one processed.
                numart = new_numart

            else:
                # Add the sentences to the numart.
                for sen in sens:
                    numart.append(E('sen', sen))

            trail.append('numart')

        elif line == '<small>' and 'minister-clause' in trail:
            # Footnote section. Contains footnotes.

            footnotes = E('footnotes')

            if trail[-1] == 'chapter':
                chapter.append(footnotes)
            else:
                art.append(footnotes)

            trail.append('footnotes')

        elif line == '<sup style="font-size:60%">' and trail[-1] in ['footnotes', 'footnote']:
            # We've found a footnote inside the footnote section!

            # Scroll past the closing tag, since we're not going to use its
            # content (see comment below).
            scroll_until(lines, '</sup>')

            # Determine the footnote number.
            # In a perfect world, we should be able to get the footnote number with a line like this:
            #
            #     footnote_nr = collect_until(lines, '</sup>').strip(')')
            #
            # But it may in fact be wrong, like in 149. gr. laga nr. 19/1940,
            # where two consecutive footnotes are numbered as 1 below the
            # article. The numbers are correct in the reference in the article
            # itself, though. For this reason, we'll deduce the correct number
            # from the number of <footnote> tags present in the current
            # <footnotes> tag. That count plus one should be the correct
            # number.
            #
            # The footnote number, and in fact other numbers, are always used
            # as strings because they really function more like names rather
            # than numbers. So we make it a string right away.
            footnote_nr = str(len(footnotes.findall('footnote')) + 1)

            # Create the footnote XML node.
            footnote = E('footnote')

            peek = lines.peek().strip()
            if matcher.check(peek, '<a href="(\/altext\/.*)">'):
                # This is a footnote regarding a legal change.
                href = 'https://www.althingi.is%s' % matcher.result()[0]

                # Retrieve the the content of the link to the external law
                # that we found.
                scroll_until(lines, '<a href="(\/altext\/.*)">')
                footnote_sen = collect_until(lines, '</a>')

                # Update the footnote with the content discovered so far.
                footnote.attrib['href'] = href
                footnote.append(E('footnote-sen', footnote_sen))

                # If the content found so far adheres to the recognized
                # pattern of external law, we'll put that information in
                # attributes as well. (It should.)
                if matcher.check(footnote_sen, 'L\. (\d+)\/(\d{4}), (\d+)\. gr\.'):
                    fn_law_nr, fn_law_year, fn_art_nr = matcher.result()
                    footnote.attrib['law-nr'] = fn_law_nr
                    footnote.attrib['law-year'] = fn_law_year
                    footnote.attrib['law-art'] = fn_art_nr

            # Some footnotes don't contain a link to an external law like
            # above but rather some arbitrary information. In these cases
            # we'll need to parse the content differently. But also, sometimes
            # a link to an external law is followed by extra content, which
            # will also be parsed here and included in the footnote.
            #
            # We will gather everything we run across into a string called
            # `gathered`, until we run into a string that indicates that
            # either this footnote section has ended, or we've run across a
            # new footnote. Either one of the expected tags should absolutely
            # appear, but even if they don't, this will still error out
            # instead of looping forever, despite the "while True" condition,
            # because "next(lines)" will eventually run out of lines.
            gathered = ''
            while True:
                if lines.peek().strip() in ['</small>', '<sup style="font-size:60%">']:
                    break
                else:
                    # The text we want is separated into lines with arbitrary
                    # indenting and HTML comments which will later be removed.
                    # As a result, meaningless whitespace is all over the
                    # place. To fix this, we'll remove whitespace from either
                    # side of the string, but add a space at the end, which
                    # will occasionally result in a double whitespace or a
                    # whitespace between tags and content. Those will be fixed
                    # later, resulting in a neat string without any unwanted
                    # whitespace.
                    gathered += next(lines).strip() + ' '

                # Get rid of HTML comments.
                gathered = re.sub(r'<!--.*?"-->', '', gathered)

                # Get rid of remaining unwanted whitespace (see above).
                gathered = gathered.replace('  ', ' ').replace('> ', '>').replace(' </', '</')

            # If extra content was found, we'll put that in a separate
            # sentence inside the footnote. If there already was a
            # <footnote-sen> because we found a link to an external law, then
            # there will be two sentences in the footnote. If this is the only
            # content found and there is no link to an external law, then
            # there will only be this one.
            if len(gathered):
                footnote.append(E('footnote-sen', gathered.strip()))

            # Explicitly state the footnote number as an attribute in the
            # footnote, so that a parser doesn't have to infer it from the
            # order of footnotes.
            footnote.attrib['nr'] = footnote_nr

            # Append the footnote to the `footnotes` node which is expected to
            # exist from an earlier iteration.
            footnotes.append(footnote)

            if lines.peek().strip() == '</small>':
                # At this point, the basic footnote XML has been produced,
                # enough to show the footnotes themselves below each article.
                # We will now see if we can parse the markers in the content
                # that the footnotes apply to, and add marker locations to the
                # footnote XML. We will then remove the markers from the text.
                # This way, the text and the marker location information are
                # separated.

                # The parent is the uppermost node to which footnotes are
                # relevant. In most cases, it's an <art> node, but it may also
                # be a <chapter> node, for example.
                parent = footnotes.getparent()

                # Closing markers have a tendency to appear after the sentence
                # that they refer to, like so:
                #
                # [Here is some sentence.] 2)
                #
                # This will result in two sentences:
                # 1. [Here is some sentence.
                # 2. ] 2)
                #
                # We'll want to combine these two, so we iterate through the
                # sentences that we have produced and find those that start
                # with closing markers and move the closing markers to the
                # previous sentence. This will make parsing end markers much
                # simpler. If the sentence where we found the closing marker
                # is empty, we'll delete it.
                #
                # In `close_mark_re` we allow for a preceding deletion mark
                # and move that as well, since it must belong to the previous
                # sentence if it precedes the closing marker that clear does.
                # (Happens in 2. mgr. 165. gr. laga nr. 19/1940.)
                close_mark_re = r'((… <sup style="font-size:60%"> \d+\) </sup>)? ?\]? ?<sup style="font-size:60%"> \d+\) </sup>)'
                nodes_to_kill = []
                for desc in parent.iterdescendants():
                    peek = desc.getnext()

                    # We have nothing to do here if the following node doesn't
                    # exist or contain anything.
                    if peek is None or peek.text is None:
                        continue

                    # Keep moving the closing markers from the next node
                    # ("peek") to the current one ("desc"), until there are no
                    # closing markers in the next node. (Probably there is
                    # only one, but you never know.)
                    while matcher.check(peek.text, close_mark_re):
                        # Get the actual closing marker from the next node.
                        stuff_to_move = matcher.result()[0]

                        # Add the closing marker to the current node.
                        desc.text += stuff_to_move

                        # Remove the closing marker from the next node.
                        peek.text = re.sub(close_mark_re, '', peek.text, 1)

                    # If there's no content left in the next node, aside from
                    # the closing markers that we just moved, then we'll put
                    # the next node on a list of nodes that we'll delete
                    # later. We can't delete it here because it will break the
                    # iteration (parent.iterdescendants).
                    if len(peek.text) == 0:
                        nodes_to_kill.append(peek)

                # Delete nodes marked for deletion.
                for node_to_kill in nodes_to_kill:
                    node_to_kill.getparent().remove(node_to_kill)

                opening_locations = []
                marker_locations = []
                for desc in parent.iterdescendants():
                    # Leave the footnotes out of this, since we're only
                    # looking for markers in text.
                    if 'footnotes' in [a.tag for a in desc.iterancestors()]:
                        continue

                    # Not interested if the node contains no text.
                    if not desc.text:
                        continue

                    # Keeps track of where we are currently looking for
                    # markers within the entity being checked.
                    cursor = 0

                    opening_found = desc.text.find('[', cursor)
                    closing_found = desc.text.find(']', cursor)
                    while opening_found > -1 or closing_found > -1:
                        if opening_found > -1 and (opening_found < closing_found or closing_found == -1):
                            # We have found an opening marker: [

                            # Indicate that our next search for an opening tag
                            # will continue from here.
                            cursor = opening_found + 1

                            # Get the ancestors of the node (see function's
                            # comments for details.)
                            ancestors = generate_ancestors(desc, parent)

                            # We now try to figure out whether we want to mark
                            # an entire entity (typically a sentence), or if
                            # we want to mark a portion of it. If we want to
                            # mark a portion, "use_words" shall be True and
                            # the footnote XML will contain something like
                            # this:
                            #
                            #    <sen words="some marked text">2</sen>
                            #
                            # Instead of:
                            #
                            #    <sen>2</sen>
                            #

                            # At this point, the variable `opening_found`
                            # contains the location of the first opening
                            # marker (the symbol "]") in the current node's
                            # text.

                            # Find the opening marker after the current one,
                            # if it exists.
                            next_opening = desc.text.find('[', opening_found + 1)

                            # Check whether the next opening marker, if it
                            # exists, is between the current opening marker
                            # and the next closing marker.
                            no_opening_between = next_opening == -1 or next_opening > closing_found

                            # Use "words" if 1) the opening marker is at the
                            # start of the sentence and 2) there is also a
                            # closing marker found but 3) there's no opening
                            # marker between the current marker and its
                            # corresponding closing marker.
                            partial_at_start = opening_found == 0 and closing_found > -1 and no_opening_between

                            # Boil this logic down into the question: to use
                            # words or not to use words?
                            use_words = opening_found > 0 or partial_at_start

                            if use_words:
                                # NOTE/TODO: We will need to add support for
                                # using "words" across multiple sentences,
                                # which is currently unsupported but happens
                                # in 1-2. málsl. 1. mgr. 95. gr. laga nr.
                                # 19/1940. We'll need to check for the closing
                                # marker in the next sentence, presumably
                                # (and, dare I mention, possibly more than one
                                # sentence into the future).

                                # We'll start with everything from the opening
                                # marker onward. Because of possible markers
                                # in the text that should end up in "words",
                                # we'll need to do a bit of processing to
                                # figure out where exactly the appropriate
                                # closing marker is located. Quite possibly,
                                # it's not simply the first one.
                                words = desc.text[opening_found + 1:]

                                # Eliminate **pairs** of opening and closing
                                # markers beyond the opening marker we're
                                # currently dealing with. When this has been
                                # accomplished, the next closing marker should
                                # be the one that goes with the opening marker
                                # that we're currently dealing with. Example:
                                #
                                #     a word [and another] that says] boo
                                #
                                # Should become:
                                #
                                #     a word and another that says] boo
                                #
                                # Note that the opening/closing marker pair
                                # around "and another" have disappeared
                                # because they came in a pair. With such pairs
                                # removed, we can conclude our "words"
                                # variable from the remaining non-paired
                                # closing marker, and the result should be:
                                #
                                #     a word and another that says
                                #
                                words = re.sub(
                                    '\[(.*?)\] <sup style="font-size:60%"> \d+\) </sup>',
                                    r'\1',
                                    words
                                )

                                # Find the first non-paired closing marker.
                                closing_index = words.find(']')

                                # Cut the "words" variable appropriately. If
                                # closing_index wasn't found, it means that
                                # the "words" actually span beyond this
                                # sentence. Instead of cutting the words
                                # string (by -1 because the closing symbol
                                # wasn't found, which would make no sense), we
                                # leave it intact. The rest of the "words"
                                # string will be placed in an <end> element by
                                # the closing-marker mechanism.
                                if closing_index > -1:
                                    words = words[:closing_index]

                                # Explicitly remove marker stuff, even though
                                # most likely it will already be gone because
                                # the marker parsing implicitly avoids
                                # including them. Such removal may leave stray
                                # space that we also clear.
                                words = strip_markers(words).strip()

                                # Add the "words" attribute to the last element.
                                ancestors[-1].attrib['words'] = words

                            # We'll "pop" this list when we find the closing
                            # marker, as per below.
                            opening_locations.append(ancestors)

                        elif closing_found > -1 and (closing_found < opening_found or opening_found == -1):
                            # We have found a closing marker: ]

                            cursor = closing_found + 1

                            # Grab the footnote number of the highlighted
                            # text. Sometimes the number is located in the
                            # next <sen> element, for example: "or not the
                            # [minister]. <sup ...> 2) </sup>". In these cases
                            # we'll need to peek into the next <sen> element.
                            # We'll do this by changing the haystack in which
                            # we look. We won't use the cursor when looking
                            # for it though, because it will definitely be the
                            # first <sup> we run into, inside the next <sen>
                            #
                            # By the way:
                            #     len('<sup style="font-size:60%">') == 27
                            if desc.text.find('<sup style="font-size:60%">', cursor) > -1:
                                haystack = desc.text
                                num_start = haystack.find('<sup style="font-size:60%">', cursor) + 27
                                num_end = haystack.find('</sup>', cursor)
                                num_text = haystack[num_start:num_end]
                                num = num_text.strip().strip(')')
                            else:
                                haystack = desc.getnext().text
                                num_start = haystack.find('<sup style="font-size:60%">') + 27
                                num_end = haystack.find('</sup>')
                                num_text = haystack[num_start:num_end]
                                num = num_text.strip().strip(')')

                            # We have figured out the starting location in the
                            # former clause of the if-sentence.
                            started_at = opening_locations.pop()

                            # Get the ancestors of the node (see function's
                            # comments for details.)
                            ancestors = generate_ancestors(desc, parent)

                            # If the start location had a "words" attribute,
                            # indicating that a specific set of words should
                            # be marked, then we'll copy that attribute here
                            # to the end location, so that the <start> and
                            # <end> tags will get truncated into a unified
                            # <location> tag...
                            if 'words' in started_at[-1].attrib:
                                # ...except, if it turns out that we're
                                # actually dealing with a different sentence
                                # than was specified in the start location,
                                # but the "words" attribute is being used, it
                                # means that a string is to be marked that
                                # spans more than one sentence.
                                #
                                # In such a case, the start location will
                                # determine the opening marker via its "words"
                                # attribute, but the end location (being
                                # processed here) will determine the closing
                                # marker with its distinct set of "words",
                                # each attribute containing the set of words
                                # contained in their respective sentences.
                                sen_nr = str(order_among_siblings(desc))
                                if desc.tag == 'sen' and sen_nr != started_at[-1].text:
                                    # Remove pairs of opening/closing markers
                                    # from the "words", so that we find the
                                    # correct closing marker. (See comment on
                                    # same process in processing of opening
                                    # markers above.)
                                    words = re.sub(
                                        '\[(.*?)\] <sup style="font-size:60%"> \d+\) </sup>',
                                        r'\1',
                                        words
                                    )
                                    words = desc.text[:desc.text.find(']')]
                                else:
                                    words = started_at[-1].attrib['words']

                                ancestors[-1].attrib['words'] = words

                            ended_at = ancestors

                            # Stuff our findings into a list of marker
                            # locations that can be appended to the footnote
                            # XML.
                            marker_locations.append({
                                'num': int(num),
                                'started_at': started_at,
                                'ended_at': ended_at
                            })

                        # Check again for the next opening and closing
                        # markers, except from our cursor, this time.
                        closing_found = desc.text.find(']', cursor)
                        opening_found = desc.text.find('[', cursor)



                    # Now that we're done processing the markers and can add
                    # them to the footnotes in XML format, we'll delete them
                    # from the text itself. This may leave spaces on the edges
                    # which we'll remove as well.
                    desc.text = strip_markers(desc.text).strip()

                if len(marker_locations):

                    # Finally, we'll start to build and add the location XML
                    # to the footnotes, out of all this information we've
                    # crunched from the text!

                    # We'll want to be able to "peek" backwards easily, so
                    # we'll use the super_iterator. We could also use
                    # enumerate() but we figure that using the peek function
                    # is more readable than playing around with iterators.
                    marker_locations = super_iter(marker_locations)

                    for ml in marker_locations:
                        # Get the marker's appropriate footnote XML.
                        footnote = footnotes.getchildren()[ml['num'] - 1]

                        # Create the location XML node itself.
                        location = E('location', {'type': 'range'})

                        # If the starting and ending locations are identical,
                        # we will only want a <location> element to denote the
                        # marker's locations.
                        started_at = ml['started_at']
                        ended_at = ml['ended_at']
                        if xml_lists_identical(started_at, ended_at):
                            for node in started_at:
                                location.append(node)
                        else:
                            # If, however, the the starting and ending
                            # locations differ and we are not denoting a
                            # region of text with "words", we'll need
                            # sub-location nodes, <start> and <end>, within
                            # the <location> element, so that the opening and
                            # closing markers can be placed in completely
                            # different places.
                            start = E('start')
                            end = E('end')
                            for node in started_at:
                                start.append(node)
                            for node in ended_at:
                                end.append(node)

                            location.append(start)
                            location.append(end)

                        # If the location XML that we're adding is identical
                        # to the previous location node in the same footnote
                        # node, then instead of adding the same location node
                        # again, we'll configure the previous one as
                        # repetitive. We assume that if the same words are
                        # marked twice, that all instances of the same words
                        # should be marked in the given element.
                        #
                        # This is done to make it easier to use the XML when
                        # the same set of words should be marked repeatedly in
                        # the same sentence.
                        prev_location = footnotes.getchildren()[ml['num'] - 2].find('location')
                        if prev_location is not None and xml_compare(prev_location, location):
                            last_item_in_prev_location = prev_location.getchildren()[-1]
                            last_item_in_prev_location.attrib['repeat'] = 'true'
                        else:
                            # Finally, we add the location node to the
                            # footnote node.
                            footnote.append(location)

            # Leave a trail saying we're done processing a footnote.
            trail.append('footnote')

    # Write the XML object to output file.
    with open(XML_FILENAME % (law_year, law_num, parliament_version), 'w') as f:
        # Importing a completely different XML library than the one we're
        # using elsewhere in the code is a bit weird, but this is the only one
        # we could find that does pretty printing with proper indenting. That
        # happens to be very important for seeing whether the end result
        # works. Since it's only used when DEBUG=True and is very much an
        # anomaly in the code, it is imported here instead of at the top of
        # the file.
        #
        # When not in DEBUG mode, we'll skip those shenanigans and write it
        # out with the same library as the one we use elsewhere.
        if settings.DEBUG:
            import xml.dom.minidom
            xml = xml.dom.minidom.parseString(etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )
            pretty_xml_as_string = xml.toprettyxml(indent='  ')
            f.write(pretty_xml_as_string)
        else:
            f.write(
                etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )


def process_law(law_id):

    stdout.write('Processing law nr. %s...' % law_id)
    stdout.flush()

    (law_num, law_year) = law_id.split('/')
    law_num = int(law_num)
    law_year = int(law_year)

    stdout.write('cleaning...')
    stdout.flush()
    clean_law(law_num, law_year)

    stdout.write('making XML...')
    stdout.flush()
    make_xml(law_num, law_year, CURRENT_PARLIAMENT_VERSION)

    stdout.write(' done\n')


def usage(exec_name, message=None):
    stderr.write('Usage: %s [law_number>/<year>] [year] [-a]\n' % exec_name)
    stderr.write('\n')
    stderr.write('Options:\n')
    stderr.write('    -a    Process all available laws.\n')
    stderr.write('\n')
    if message:
        stderr.write('Error: %s\n' % message)
    quit(1)


def main(argv):

    law_ids = set()
    for arg in argv:
        if arg == '-a':
            for filename in os.listdir(os.path.dirname(LAW_FILENAME)):
                if re.match('^\d{7}\.html$', filename):
                    law_year = int(filename[0:4])
                    law_num = int(filename[4:7])
                    law_id = '%d/%d' % (law_num, law_year)
                    law_ids.add(law_id)
        elif re.match('^\d{4}$', arg):
            for filename in os.listdir(os.path.dirname(LAW_FILENAME)):
                if re.match('^%s\d{3}\.html$' % arg, filename):
                    law_year = int(filename[0:4])
                    law_num = int(filename[4:7])
                    law_id = '%d/%d' % (law_num, law_year)
                    law_ids.add(law_id)
        elif re.match('^\d{1,4}\/\d{4}$', arg):
            law_ids.add(arg)

    if len(law_ids) == 0:
        usage(argv[0], 'No files matched the given criteria.')

    for law_id in law_ids:
        process_law(law_id)


try:
    main(sys.argv)
except KeyboardInterrupt:
    quit()
except Exception as e:
    if settings.DEBUG:
        raise
    else:
        stderr.write('Error: %s\n' % e)
