#!/usr/bin/env python
# althingi-document-cleaner
# Version 0.1

from bs4 import BeautifulSoup
import codecs
import urllib
import re
import roman

import os
import sys

import settings

from lxml import etree
from lxml.builder import E
from sys import stderr
from sys import stdout

from contenthandlers import separate_sentences

from utils import Matcher
from utils import strip_markers
from utils import super_iter
from utils import xml_lists_identical

CURRENT_PARLIAMENT_VERSION = '148a'

LAW_FILENAME = CURRENT_PARLIAMENT_VERSION + '/%d%s.html' # % (law_year, law_num)
CLEAN_FILENAME = 'cleaned/%d-%d.html' # % (law_year, law_num)
XML_FILENAME = 'xml/%d.%d.%s.xml' # % (law_year, law_num, parliament_version)

def clean_content(content):
    # Decode ISO-8859-1 character encoding.
    #content = content.decode('ISO-8859-1')

    # Replace HTML-specific space for normal space.
    content = content.replace('&nbsp;', ' ')

    # Make sure that horizontal bar tags are closed properly.
    content = content.replace('<hr>', '<hr />')

    # Make sure that linebreak tags are closed properly.
    content = content.replace('<br>', '<br />')

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove markers for previous changes and removed content.
        content = content.replace('[', '').replace(']', '')
        content = content.replace('…', '').replace('&hellip;', '')

    # Remove links to website
    #strings_to_remove = (
    #    u'Ferill málsins á Alþingi.',
    #    u'Frumvarp til laga.',
    #)
    #for s in strings_to_remove:
    #    content = content.replace(s, '')

    # Make sure that image tags are closed properly.
    e = re.compile(r'<img ([^>]*)>', re.IGNORECASE)
    content = e.sub(r'<img \1 />', content)

    # Remove <a id=""> tags which are unclosed and seem without purpose.
    # For example, see source of page: http://www.althingi.is/altext/143/s/0470.html
    content = content.replace('<a id="">', '')

    # Find the law content and exit if it does not exist
    soup_law = BeautifulSoup(content, 'html5lib').find('html')
    if soup_law is None:
        return None

    soup = BeautifulSoup(soup_law.__str__(), 'html5lib') # Parse the law content

    if not settings.FEATURES['PARSE_MARKERS']:
        # Remove superscripts indicating previous change. Only removes them when
        # they are found outside of footnotes.
        superscripts = soup.find_all('sup')
        for s in superscripts:
            if s.parent.name != 'small' and re.match('^\d{1,3}\)$', s.text):
                s.extract()

    # Remove links
    #anchors = soup.find_all('a')
    #for a in anchors:
    #    a.replace_with(a.text)

    # Remove tags entirely irrelevant to content
    #tags_to_remove = ['small'] # Previously also ['hr', 'script', 'noscript', 'head']
    #for target_tag in tags_to_remove:
    #    [s.extract() for s in soup(target_tag)]

    # Remove empty tags, but only if they're empty
    empty_tags_to_remove = ['p', 'h2', 'i']
    for target_tag in empty_tags_to_remove:
        empty_tags = soup.find_all(lambda tag: tag.name == target_tag and not tag.contents and (
            tag.string is None or not tag.string.strip()
        ))
        [empty_tag.extract() for empty_tag in empty_tags]

    # Keep consecutive <br />s only at 2 at most
    brs_in_a_row = 0
    all_tags = soup.find_all()
    for t in all_tags:
        if t.name == 'br':
            if brs_in_a_row >= 2:
                t.extract()
            else:
                brs_in_a_row = brs_in_a_row + 1
        else:
            brs_in_a_row = 0

    # Replace <html> and <body> tags' with <div>s.
    '''
    body_tag = soup.find('body')
    if body_tag is not None:
        body_tag.attrs['id'] = 'body_tag'
        body_tag.name = 'div'
    html_tag = soup.find('html')
    html_tag.attrs['id'] = 'html_tag'
    html_tag.name = 'div'
    '''

    # Add charset tag
    charset_tag = soup.new_tag('meta', charset='utf-8')
    soup.insert(0, charset_tag)

    xhtml = soup.prettify()

    # Final cleanup at text-stage.
    xhtml = xhtml.replace(' <!-- Tab -->\n  ', '&nbsp;&nbsp;&nbsp;&nbsp;')

    return xhtml


def clean_law(law_num, law_year):
    with codecs.open(LAW_FILENAME % (law_year, str(law_num).zfill(3)), 'r', 'ISO-8859-1') as infile:
        raw_content = infile.read()
        infile.close()

    content = clean_content(raw_content)

    if content is None:
        stdout.write(' failed.\n')
        stderr.write('Error: Law %d/%d does not seem to exist\n' % (law_year, law_num))
        quit(1)

    if not os.path.isdir(os.path.dirname(CLEAN_FILENAME)):
        os.mkdir(os.path.dirname(CLEAN_FILENAME))

    with open(CLEAN_FILENAME % (law_year, law_num), 'w') as clean_file:
        clean_file.write(content)
        clean_file.close()


def make_xml(law_num, law_year, parliament_version):

    # Make sure that the XML output directory exists.
    if not os.path.isdir(os.path.dirname(XML_FILENAME)):
        os.mkdir(os.path.dirname(XML_FILENAME))

    # Construct the output XML object.
    law = E.law('', {'nr': str(law_num), 'year': str(law_year), 'parliament': parliament_version})

    # Open and read the cleaned HTML version of the law.
    with open(CLEAN_FILENAME % (law_year, law_num)) as clean_file:
        lines = super_iter(clean_file.readlines())
        clean_file.close()

    # Keeps track of the turn of events. We can query this list to check for
    # example whether the name of the document has been processed, or what the
    # last thing to be processed was. This gives us context when determining
    # what to do next.
    trail = ['start']

    # See utils.py.
    matcher = Matcher()

    # Functions for collecting heaps of text, then returning it all in one go
    # and resetting the collection for the next time we need to collect a
    # bunch of text.
    def collect(string):
        if not hasattr(collect, 'collection'):
            collect.collection = []
        collect.collection.append(string.strip())
    def uncollect():
        result = ' '.join(collect.collection).strip()
        collect.collection = []
        return result

    # Will collect lines until the given string is found, and then return the
    # collected lines.
    def collect_until(lines, end_string):
        done = False
        while not done:
            line = next(lines).strip()
            if matcher.check(line, end_string):
                done = True
                continue
            collect(line)

        total = uncollect().strip()

        return total

    # Scrolls the lines until the given string is found. It works internally
    # the same as the collect_until-function, but is provided here with a
    # different name to provide a semantic distinction in the code below.
    scroll_until = collect_until

    # Objects that help us figure out the current state of affairs. These
    # variables are used between iterations, meaning that whenever possible,
    # their values should make sense at the end of the processing of a
    # particular line or clause. Never put nonsense into them because it will
    # completely confuse the processing elsewhere.
    chapter = None
    art = None
    subart = None

    # The cleaned document that we're processing is expected to put every tag,
    # both its opening and closing, on a separate line. This allows us to
    # browse the HTML contents on a per-line basis.
    for line in lines:
        line = line.strip()

        if line == '<h2>':
            # Parse law name.
            name = collect_until(lines, '</h2>')

            law.append(E.name(name))

            trail.append('name')

        elif line == '<strong>':
            if trail[-1] == 'name':
                # Parse the num and date, which appears directly below the law name.
                num_and_date = collect_until(lines, '</strong>')

                law.append(E('num-and-date', num_and_date))

                trail.append('num-and-date')

        elif line == '<hr/>' and trail[-1] == 'num-and-date':
            # Parse the whole clause about which minister the law refers to.
            # It contains HTML goo, but we'll just let it float along. It's
            # not even certain that we'll be using it, but there's no harm in
            # keeping it around.
            minister_clause = collect_until(lines, '<hr/>')

            law.append(E('minister-clause', minister_clause))

            trail.append('minister-clause')

        # Chapters are found by finding a <b> tag that comes right after a
        # <br/> tag that occurs after the ministerial clause is done.
        elif line == '<b>' and 'minister-clause' in trail and lines.peek(-1).strip() == '<br/>':
            # Parse what we will believe to be a chapter.

            # Chapter names are a bit tricky. They may be divided into two <b>
            # clauses, in which case the former one is what we call a nr-title
            # (I. kafli, II. kafli etc.), and then a name describing its
            # content (Almenn ákvæði, Tilgangur og markmið etc.).
            #
            # Sometimes however, there is only one <b> and not two. In these
            # cases, there is no nr-title and only a name. Here we check 3
            # lines into the future to see if there's another <b> tag coming
            # (because we know that the former <b>text</b> clause will be
            # precisely 3 lines), and if so, we'll process the nr-title and
            # name, but otherwise we will only process the name and skip
            # nr-title altogether.
            if lines.peek(3).strip() == '<b>':
                chapter_nr_title = collect_until(lines, '</b>')

                # Let's see if we can figure out the number of this chapter.
                # We're going to assume the format "II. kafli" for the second
                # chapter, and "II. kafli B." for the second chapter B, and in
                # those examples, nr-titles will be "2" and "2b" respectively.
                t = strip_markers(chapter_nr_title)
                nr = str(roman.fromRoman(t[0:t.index('.')]))
                alpha = t[t.index('kafli') + 6:].strip('.')
                if alpha:
                    nr += alpha.lower()
                del t

                scroll_until(lines, '<b>')
                chapter_name = collect_until(lines, '</b>')

                chapter = E.chapter(
                    {'nr': str(nr)},
                    E('nr-title', chapter_nr_title),
                    E('name', chapter_name)
                )

            else:
                chapter_name = collect_until(lines, '</b>')

                chapter = E.chapter(
                    E('name', chapter_name)
                )

            # Some laws have a chapter for temporary clauses, which may be
            # named something like "Bráðabirgðaákvæði", "Ákvæði til
            # bráðabirgða" and probably something else as well. We will assume
            # that a chapter name that includes that string "bráðabirgð" is a
            # chapter for temporary clauses and furthermore that the string
            # does NOT appear in any other kind of chapter.
            if 'bráðabirgð' in chapter_name.lower():
                chapter.attrib['type'] = 'temporary-clauses'

            law.append(chapter)

            trail.append('chapter')

        elif line == '<img alt="" height="11" src="/lagas/sk.jpg" width="11"/>':
            # Parse an article.
            scroll_until(lines, '<b>')
            art_nr_title = collect_until(lines, '</b>')

            clean_art_nr_title = strip_markers(art_nr_title)

            # Hopefully this stays None. Not because anything will break
            # otherwise, but because Roman numerals suck ass.
            art_roman_nr = None

            # Analyze the displayed article name.
            try:
                # A typical article is called something like "13. gr." or
                # "13. gr. b". The common theme among typical articles is that
                # the string ". gr." will appear in them somewhere. Anything
                # before it is the article number. Anything after it, is an
                # extra thing which is appended to article names when new
                # articles are placed between two existing ones. For example,
                # if there already are articles 13 and 14 but the legislature
                # believes that a new article properly belongs between them,
                # the article will probably be called "13. gr. a". We would
                # want that translated into an sortable `art_nr` f.e. "13a".

                # Find index of common string. If the string does not exist,
                # it's some sort of a special article. A ValueError will be
                # raised and we'll deal with it below.
                gr_index = clean_art_nr_title.index('. gr.')

                # Determine the numeric part of the article's name.
                art_nr = clean_art_nr_title[0:gr_index]

                # Occasionally an article number actually covers a range, so
                # far only seen when multiple articles have been removed and
                # are thus collectively empty. We check for the pattern here
                # and reconstruct it if needed.
                if matcher.check(clean_art_nr_title, '(\d+)\.–(\d+)'):
                    from_art_nr, to_art_nr = matcher.result()
                    art_nr = '%s-%s' % (from_art_nr, to_art_nr)

                # Check if there is an extra part to the name which we'll want
                # appended to the `art_nr`.
                #
                # Note: len('.gr.') + 1 = 6
                art_nr_extra = clean_art_nr_title[gr_index+6:].strip().strip('.')
                if len(art_nr_extra):
                    art_nr = '%s%s' % (art_nr, art_nr_extra)

            except ValueError:
                # This means that the article's name is formatted in an
                # unconventional way. Typically this occurs only in temporary
                # clauses that tend to be numbered with some stupid fucking
                # Roman bullshit.
                art_nr = None
                try:
                    art_roman_nr = str(roman.fromRoman(clean_art_nr_title.strip('.')))
                except roman.InvalidRomanNumeralError:
                    # Good. Fuck Roman numerals.
                    pass

            # Create the tags, configure them and append to the chapter.
            art = E('art', E('nr-title', art_nr_title))
            if art_nr is not None:
                art.attrib['nr'] = art_nr
            if art_roman_nr is not None:
                art.attrib['roman-nr'] = art_roman_nr
                art.attrib['number-type'] = 'roman'
            chapter.append(art)

            # Check if the next line is an <em>, because if so, then the
            # article has a name title and we need to grab it. Note that not
            # all articles have names.
            if lines.peek().strip() == '<em>':
                scroll_until(lines, '<em>')
                art_name = collect_until(lines, '</em>')

                art.append(E('name', art_name))

            trail.append('art-nr')

            # There can be no current subarticle if we've just discovered a
            # new article.
            subart = None

        elif matcher.check(line, '<img .+ id="[GB](\d+)[A-Z]?M(\d+)" src=".+\/hk.jpg" .+\/>'):
            art_nr, subart_nr = matcher.result()

            content = collect_until(lines, '<br/>')

            subart = E('subart', {'nr': subart_nr })
            sens = separate_sentences(content)
            for sen in sens:
                subart.append(E('sen', sen))
            art.append(subart)

            trail.append('subart')

        elif matcher.check(line, '<span id="G(\d+)([0-9A-Z]*)L(\d+)">'):
            # fake_numart_nr is named so because it doesn't give the current
            # numart_nr. Not only is it always a digit, when in fact a real
            # numart_nr can be alphabetical, but even if we only had numbers,
            # they would still be wrong in some recursive lists. This is why
            # we won't trust it, and will rather analyze the content of the
            # next line, which will contain the correct numart_nr in the
            # correct type.
            numart_nr = strip_markers(lines.peek().strip().strip('.'))

            # Dictates where we will place this numart.
            parent = None

            if trail[-1] == 'numart':
                # `prev_numart` is only defined here for readability. `numart` hasn't
                # been set yet, so it's still equivalent to the previous
                # `numart`, so technically we could just use `numart` instead.
                # But `numart` is going to change later, so we'd rather be
                # clear on the code semantics when using `numart` but still
                # referring to the previous one.
                prev_numart = numart

                prev_numart_nr = prev_numart.attrib['nr']

                # Check if the type of the numart has changed from numeric to
                # alphabetic or vice versa.
                different_type = any([
                    prev_numart_nr.isdigit() and not numart_nr.isdigit(),
                    not prev_numart_nr.isdigit() and numart_nr.isdigit()
                ])

                if prev_numart_nr.isdigit():
                    expected_numart_nr = str(int(prev_numart_nr) + 1)
                else:
                    expected_numart_nr = chr(int(ord(prev_numart_nr)) + 1)

                if expected_numart_nr != numart_nr or different_type:
                    if numart_nr == 'a' or (numart_nr.isdigit() and int(numart_nr) == 1):
                        # A new list has started within the one we were
                        # already processing, which we can tell because there
                        # was a `numart` before this one, but this `numart`
                        # says it's at the beginning, being either 'a' or 1.
                        # In this case, we'll choose the previous `numart` as
                        # the parent, so that this new list will be inside the
                        # previous one.
                        parent = prev_numart
                    else:
                        # A different list is being handled now, but it's not
                        # starting at the beginning (is neither 'a' nor 1).
                        # This means that we've been dealing with a sub-list
                        # which has now finished, so we want to continue
                        # appending this `numart` to the parent of the parent
                        # of the list we've been working on recently, which is
                        # the same parent as the nodes that came before we
                        # started the sub-list.
                        parent = prev_numart.getparent().getparent()
                else:
                    # This `numart` is simply the next one, so we'll want to
                    # append it to whatever node that the previous `numart`
                    # was appended to.
                    parent = prev_numart.getparent()

            # A parent may already be set above if `numart` currently being
            # handled is not the first one in its parent article/subarticle.
            # However, if it is indeed the first one, we need to figure out
            # where to place it. It can be placed wither in a subarticle or in
            # some cases, directly into an article without a subarticle.
            if parent is None:
                if subart is not None:
                    parent = subart
                else:
                    # We sure as $h17 assume "art" exists.
                    parent = art

            # Create numerical article.
            numart = E('numart', {'nr': numart_nr })

            # Add the numerical article to its parent.
            parent.append(numart)

            numart_nr_title = collect_until(lines, '</span>')
            numart.append(E('nr-title', numart_nr_title))
            if not numart_nr_title.strip('.').strip('[').isdigit():
                numart.attrib.update({'type': 'alphabet'})

            if lines.peek().strip() == '<i>':
                # Looks like this numerical article has a name.
                scroll_until(lines, '<i>')
                numart_name = collect_until(lines, '</i>')

                numart.append(E('name', numart_name))

            content = collect_until(lines, '<br/>')

            for sen in separate_sentences(content):
                numart.append(E('sen', sen))

            trail.append('numart')

        elif line == '<small>' and 'minister-clause' in trail:
            # Footnote section. Contains footnotes.

            footnotes = E('footnotes')

            if trail[-1] == 'chapter':
                chapter.append(footnotes)
            else:
                art.append(footnotes)

            trail.append('footnotes')

        elif line == '<sup style="font-size:60%">' and trail[-1] in ['footnotes', 'footnote']:
            # We've found a footnote inside the footnote section!

            footnote_nr = collect_until(lines, '</sup>').strip(')')

            peek = lines.peek().strip()
            if matcher.check(peek, '<a href="(\/altext\/.*)">'):
                # This is a footnote regarding a legal change.
                href = 'https://www.althingi.is%s' % matcher.result()[0]

                scroll_until(lines, '<a href="(\/altext\/.*)">')
                footnote_sen = collect_until(lines, '</a>')

                footnote = E('footnote', {'href': href}, E('footnote-sen', footnote_sen))

                if matcher.check(footnote_sen, 'L\. (\d+)\/(\d{4}), (\d+)\. gr\.'):
                    fn_law_nr, fn_law_year, fn_art_nr = matcher.result()
                    footnote.attrib['nr'] = fn_law_nr
                    footnote.attrib['year'] = fn_law_year
                    footnote.attrib['art'] = fn_art_nr

                footnotes.append(footnote)

                trail.append('footnote')

            else:
                # We will gather everything we run across into a string called
                # `gathered`, until we run into a string that indicates that
                # either this footnote section has ended, or we've run across
                # a new footnote.
                #
                # Either one of the expected tags should absolutely appear,
                # but even if they don't, this will still error out instead of
                # looping forever, despite the "while True" condition, because
                # "next(lines)" will eventually run out of lines.
                gathered = ''
                while True:
                    if lines.peek().strip() in ['</small>', '<sup style="font-size:60%">']:
                        break
                    else:
                        # The text we want is separated into lines with
                        # arbitrary indenting and HTML comments which will
                        # later be removed. As a result, meaningless
                        # whitespace is all over the place. To fix this, we'll
                        # remove whitespace from either side of the string,
                        # but add a space at the end, which will occasionally
                        # result in a double whitespace or a whitespace
                        # between tags and content. Those will be fixed later,
                        # resulting in a neat string without any unwanted
                        # whitespace.
                        gathered += next(lines).strip() + ' '

                # Get rid of HTML comments.
                gathered = re.sub(r'<!--.*?"-->', '', gathered)

                # Get rid of remaining unwanted whitespace (see above).
                gathered = gathered.replace('  ', ' ').replace('> ', '>').replace(' </', '</').strip()

                # Create the footnote node with the gathered content.
                footnote = E('footnote', E('footnote-sen', gathered))

                # Append the footnote to the `footnotes` node which is expected to exist from an earlier iteration.
                footnotes.append(footnote)

                trail.append('footnote')

            if lines.peek().strip() == '</small>':
                # At this point, the basic footnote XML has been produced,
                # enough to show the footnotes themselves below each article.
                # We will now see if we can parse the markers in the content
                # that the footnotes apply to, and add marker locations to the
                # footnote XML. We will then remove the markers from the text.
                # This way, the text and the marker location information are
                # separated.

                # Check the content for markers.
                parent = footnotes.getparent()
                opening_locations = []
                marker_locations = []
                for desc in parent.iterdescendants():
                    # Leave the footnotes out of this, since we're only
                    # looking for markers in text.
                    if 'footnotes' in [a.tag for a in desc.iterancestors()]:
                        continue

                    # Not interested if the node contains no text.
                    if not desc.text:
                        continue

                    text = desc.text # Short-hand.

                    if desc.tag == 'sen':
                        # Sentences are not formally numbered in the XML, so
                        # we have to infer their numbers from their location
                        # within their parent nodes.
                        #
                        # Note that sen_nr is not necessarily ever used. In
                        # fact, the <sen> node may not even be added. Last but
                        # not least, it may be removed, if it is found to
                        # contain no relevant information once we're done
                        # processing.
                        for i, sibling in enumerate(desc.getparent().findall('sen')):
                            if sibling == desc:
                                sen_nr = str(i + 1)
                                break

                    # Sometimes markers are not placed according to an entire
                    # entity, such as subarticle or sentence, but rather by a
                    # fraction of text within it. This can be determined by
                    # checking whether an opening marker occurs elsewhere than
                    # at the beginning of the entity. When this occurs, the
                    # closing marker is pre-emptively found and we figure out
                    # what "words" are between them. Those words are then
                    # added to the footnote location XML.
                    words = ''

                    # Keeps track of where we are currently looking for
                    # markers within the entity being checked.
                    cursor = 0

                    opening_found = desc.text.find('[', cursor)
                    closing_found = desc.text.find(']', cursor)
                    while opening_found > -1 or closing_found > -1:
                        if opening_found > -1 and (opening_found < closing_found or closing_found == -1):
                            # We have found an opening marker: [

                            # Indicate that our next search for an opening tag
                            # will continue from here.
                            cursor = opening_found + 1

                            # Locations of markers in footnote XML are denoted
                            # as a list of tags, whose name correspond to the
                            # tag name where the marker is to be located, and 
                            # whose value represents the target node's "nr"
                            # attribute. Example:
                            #
                            # <art nr="5">
                            #   <subart nr="1">
                            #     <sen>[Notice the markers?]</sen>
                            #   </subart>
                            # </art>
                            #
                            # This will result in location XML in the footnote
                            # XML as such:
                            #
                            # <location>
                            #   <art>5</art>
                            #   <subart>1</subart>
                            # </location>
                            #
                            # To achieve this, we iterate through the
                            # ancestors of the node currently being processed.
                            # For each ancestor that we find, we add to the
                            # location XML.
                            ancestors = []
                            for ancestor in desc.iterancestors():
                                ancestors.insert(0, E(ancestor.tag, ancestor.attrib['nr']))
                                if ancestor == parent:
                                    # We're not interested in anything
                                    # beyond the parent node.
                                    break

                            # Normally, we don't want to add sentences in
                            # footnotes, because they're not formally
                            # numbered. If we do want to add it, we'll do it
                            # under special circumstances later in the code.
                            if desc.tag != 'sen':
                                ancestors.append(E(desc.tag))

                            # If an opening markers is found anywhere else
                            # than at the beginning, then it's around a
                            # fraction of the text, instead of engulfing an
                            # entire entity, such as a subarticle.
                            if opening_found > 0:
                                closing_index = desc.text.find(']', opening_found)
                                if closing_index == -1:
                                    # If the closing marker isn't found in
                                    # this node, then it must be in the next
                                    # one (probably at the beginning). This is
                                    # only likely to happen near the end of a
                                    # subarticle/numarticle, but when it does,
                                    # we'll grab the content from the next
                                    # node, up to the closing marker. Almost
                                    # certainly, there will be none, but we'll
                                    # grab it, just in case.
                                    next_text = desc.getnext().text
                                    words += desc.text[opening_found + 1:] + next_text[0:next_text.find(']')]
                                else:
                                    words = desc.text[opening_found + 1:closing_index]
                                ancestors.append(E(desc.tag, {'words': words}, sen_nr))

                            # We'll "pop" this list when we find the closing
                            # marker, as per below.
                            opening_locations.append(ancestors)

                        elif closing_found > -1 and (closing_found < opening_found or opening_found == -1):
                            # We have found a closing marker: ]

                            cursor = closing_found + 1

                            # Grab the footnote number of the highlighted
                            # text. Sometimes the number is located in the
                            # next <sen> element, for example: "or not the
                            # [minister]. <sup ...> 2) </sup>". In these cases
                            # we'll need to peek into the next <sen> element.
                            # We'll do this by changing the haystack in which
                            # we look. We won't use the cursor when looking
                            # for it though, because it will definitely be the
                            # first <sup> we run into, inside the next <sen>
                            #
                            # By the way:
                            #     len('<sup style="font-size:60%">') == 27
                            if desc.text.find('<sup style="font-size:60%">', cursor) > -1:
                                haystack = desc.text
                                num_start = haystack.find('<sup style="font-size:60%">', cursor) + 27
                                num_end = haystack.find('</sup>', cursor)
                                num_text = haystack[num_start:num_end]
                                num = num_text.strip().strip(')')
                            else:
                                haystack = desc.getnext().text
                                num_start = haystack.find('<sup style="font-size:60%">') + 27
                                num_end = haystack.find('</sup>')
                                num_text = haystack[num_start:num_end]
                                num = num_text.strip().strip(')')

                            # We have figured out the starting location in the
                            # former clause of the if-sentence.
                            started_at = opening_locations.pop()

                            # Figure out the end location. Same deal as when
                            # figuring out the opening marker's location, see
                            # comments above.
                            ancestors = []
                            for ancestor in desc.iterancestors():
                                ancestors.insert(0, E(ancestor.tag, ancestor.attrib['nr']))
                                if ancestor == parent:
                                    # We're not interested in anything beyond
                                    # the parent node.
                                    break

                            # See comment for opening marker.
                            if desc.tag != 'sen':
                                ancestors.append(E(desc.tag))

                            # If 'words' were used to designate markers, then
                            # we shouldn't have an end location at all. To
                            # achieve this, we simply make the end-location
                            # identical to start location (assuming, of
                            # course, that the rest of the nodes are indeed
                            # identical), so they will be truncated into...
                            #
                            #     <location>...</location>
                            #
                            # ...instead of:
                            #
                            #     <location>
                            #       <start>...</start>
                            #       <end>...</end>
                            #     </location>
                            #
                            # The truncating mechanism comes later. Right here
                            # we're just making sure that they are the same,
                            # if appropriate, so that the truncating mechanism
                            # can catch it.
                            if words:
                                ancestors.append(E(desc.tag, {'words': words}, sen_nr))
                                words = None

                            ended_at = ancestors

                            # Stuff our findings into a list of marker
                            # locations that can be appended to the footnote
                            # XML.
                            marker_locations.append({
                                'num': int(num),
                                'subart_nr': desc.getparent().attrib['nr'],
                                'art_nr': parent.attrib['nr'],
                                'started_at': started_at,
                                'ended_at': ended_at
                            })

                        # Check again for the next opening and closing
                        # markers, except from our cursor, this time.
                        closing_found = desc.text.find(']', cursor)
                        opening_found = desc.text.find('[', cursor)

                    # Now that we're done processing the markers and can add
                    # them to the footnotes in XML format, we'll delete them
                    # from the text itself. This may leave spaces on the edges
                    # which we'll remove as well.
                    desc.text = strip_markers(desc.text).strip()

                    # In fact, if it turns out that this is an empty sentence
                    # node (presumably because all the juicy info has been
                    # sucked out of it), we'll just delete it.
                    if desc.tag == 'sen' and desc.text.strip() == '':
                        desc.getparent().remove(desc)

                if len(marker_locations):

                    # Finally, we'll start to build and add the location XML
                    # to the footnotes, out of all this information we've
                    # crunched from the text!

                    for ml in marker_locations:
                        # Get the marker's appropriate footnote XML.
                        footnote = footnotes.getchildren()[ml['num'] - 1]

                        # Create the location XML node itself and add it to
                        # the footnote.
                        location = E('location', {'type': 'range'})
                        footnote.append(location)

                        # If the starting and ending locations of the
                        # opening/closing markers are in different entities,
                        # we'll need to communicate that with special
                        # subnodes, aptly named "start" and "end".
                        if not xml_lists_identical(ml['started_at'], ml['ended_at']):
                            start = E('start')
                            end = E('end')
                            for node in ml['started_at']:
                                start.append(node)
                            for node in ml['ended_at']:
                                end.append(node)

                            location.append(start)
                            location.append(end)
                        else:
                            # Otherwise, we'll just stash what we found in the
                            # location XML.
                            for node in ml['started_at']:
                                location.append(node)

    # Write the XML object to output file.
    with open(XML_FILENAME % (law_year, law_num, parliament_version), 'w') as f:
        # Importing a completely different XML library than the one we're
        # using elsewhere in the code is a bit weird, but this is the only one
        # we could find that does pretty printing with proper indenting. That
        # happens to be very important for seeing whether the end result
        # works. Since it's only used when DEBUG=True and is very much an
        # anomaly in the code, it is imported here instead of at the top of
        # the file.
        #
        # When not in DEBUG mode, we'll skip those shenanigans and write it
        # out with the same library as the one we use elsewhere.
        if settings.DEBUG:
            import xml.dom.minidom
            xml = xml.dom.minidom.parseString(etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )
            pretty_xml_as_string = xml.toprettyxml(indent='  ')
            f.write(pretty_xml_as_string)
        else:
            f.write(
                etree.tostring(
                    law,
                    pretty_print=True,
                    xml_declaration=True,
                    encoding='utf-8'
                ).decode('utf-8')
            )


def process_law(law_id):

    stdout.write('Processing law nr. %s...' % law_id)
    stdout.flush()

    (law_num, law_year) = law_id.split('/')
    law_num = int(law_num)
    law_year = int(law_year)

    stdout.write('cleaning...')
    stdout.flush()
    clean_law(law_num, law_year)

    stdout.write('making XML...')
    stdout.flush()
    make_xml(law_num, law_year, CURRENT_PARLIAMENT_VERSION)

    stdout.write(' done\n')


def usage(exec_name, message=None):
    stderr.write('Usage: %s [law_number>/<year>] [year] [-a]\n' % exec_name)
    stderr.write('\n')
    stderr.write('Options:\n')
    stderr.write('    -a    Process all available laws.\n')
    stderr.write('\n')
    if message:
        stderr.write('Error: %s\n' % message)
    quit(1)


def main(argv):

    law_ids = set()
    for arg in argv:
        if arg == '-a':
            for filename in os.listdir(os.path.dirname(LAW_FILENAME)):
                if re.match('^\d{7}\.html$', filename):
                    law_year = int(filename[0:4])
                    law_num = int(filename[4:7])
                    law_id = '%d/%d' % (law_num, law_year)
                    law_ids.add(law_id)
        elif re.match('^\d{4}$', arg):
            for filename in os.listdir(os.path.dirname(LAW_FILENAME)):
                if re.match('^%s\d{3}\.html$' % arg, filename):
                    law_year = int(filename[0:4])
                    law_num = int(filename[4:7])
                    law_id = '%d/%d' % (law_num, law_year)
                    law_ids.add(law_id)
        elif re.match('^\d{1,4}\/\d{4}$', arg):
            law_ids.add(arg)

    if len(law_ids) == 0:
        usage(argv[0], 'No files matched the given criteria.')

    for law_id in law_ids:
        process_law(law_id)


try:
    main(sys.argv)
except KeyboardInterrupt:
    quit()
except Exception as e:
    if settings.DEBUG:
        raise
    else:
        stderr.write('Error: %s\n' % e)
